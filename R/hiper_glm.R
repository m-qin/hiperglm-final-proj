#' @export
hiper_glm <- function(design, outcome, model_name = "linear", option = list(), noise_var = 1) {
  supported_model <- c("linear", "logit", "poisson")
  if (!(model_name %in% supported_model)) {
    stop(sprintf("The model %s is not supported.", model_name))
  }
  model <- new_regression_model(design, outcome, model_name, noise_var)
  hglm_out <- find_mle(model, option)
  class(hglm_out) <- "hglm"
  return(hglm_out)
}

new_regression_model <- function(design, outcome, model_name, noise_var = 1) {
  model <- list(design = design, outcome = outcome, name = model_name, noise_var = noise_var)
  class(model) <- "model"
  return(model)
}

find_mle <- function(model, option) {
  if (is.null(option$mle_solver)) {
    if (model$name == 'linear') {
      result <- solve_via_least_sq(model)
    } else {
      result <- solve_via_newton(model, option)
    }
  } else { # if option$mle_solver == 'BFGS'
    result <- solve_via_optim(model, option)
  }
  return(result)
}

solve_via_least_sq <- function(model) {
  design <- model$design; outcome <- model$outcome; noise_var <- model$noise_var
  ls_result <- solve_least_sq_via_qr(design, outcome, noise_var) # not yet implemented: non-scalar noise_var (e.g., GLS)
  mle_coef <- ls_result$solution
  noise_var <- mean((outcome - design %*% mle_coef)^2)
  n_obs <- nrow(design); n_pred <- ncol(design)
  noise_var <- noise_var / (1 - n_pred / n_obs) 
    # Use the same nearly-unbiased estimator as in `stats::lm`
  cov_est <- noise_var * invert_gram_mat_from_qr(ls_result$R)
  return(list(coef = mle_coef, cov_est = cov_est))
}

solve_via_newton <- function(model, option) {
  n_max_iter <- ifelse(is.null(option$n_max_iter), 25L, option$n_max_iter)
  rel_tol <- ifelse(is.null(option$rel_tol), 1e-6, option$rel_tol)
  abs_tol <- ifelse(is.null(option$abs_tol), 1e-6, option$abs_tol)
  coef_est <- rep(0, ncol(model$design))
  n_iter <- 0L
  max_iter_reached <- FALSE
  converged <- FALSE
  curr_loglik <- calc_loglik(model, coef_est)
  while (!(converged || max_iter_reached)) {
    prev_loglik <- curr_loglik
    coef_est <- take_one_newton_step(model, coef_est, option)
    curr_loglik <- calc_loglik(model, coef_est)
    converged <- (
      2 * abs(curr_loglik - prev_loglik) < (abs_tol + rel_tol * abs(curr_loglik))
    )
    n_iter <- n_iter + 1L
    max_iter_reached <- (n_iter == n_max_iter)
  }
  if (max_iter_reached && !converged) {
    warning("Newton's method did not converge. The estimates may be meaningless.")
  }
  cov_est <- - calc_hessian_inverse(model, coef_est)
  return(list(
    coef = coef_est, cov = cov_est, 
    converged = converged, n_iter = n_iter
  ))
}

take_one_newton_step <- function(model, coef_est, option) {
  solver <- ifelse(is.null(option$solver), "weighted-least-sq", option$solver)
  if (solver == "weighted-least-sq") {
    loglink_grad <- calc_loglink_deriv(model, coef_est, order = 1)
    weight <- calc_loglink_deriv(model, coef_est, order = 2)
    if (any(weight == 0)) {
      stop("Exact 0 or 1 found in predicted probability while solving for MLE.")
        # TODO: pursue alternative path forward in this case. Maybe just fall 
        # back on a Newton step with explicit computation of weighted Hessian. 
    }
    ls_target_vec <- loglink_grad / weight
    coef_update <- solve_least_sq_via_qr(model$design, ls_target_vec, weight)$solution
  } else { # if solver == "normal-eq"
    grad <- calc_grad(model, coef_est)
    hess <- calc_hessian(model, coef_est)
    coef_update <- - solve(hess, grad)
  }
  coef_est <- coef_est + coef_update
  return(coef_est = coef_est)
}

solve_via_optim <- function(model, option) {
  init_coef <- rep(0, ncol(model$design))
  obj_fn <- function (coef) {
    calc_loglik(model, coef)
  }
  obj_grad <- function (coef) {
    calc_grad(model, coef)
  }
  optim_result <- stats::optim(
    init_coef, obj_fn, obj_grad, method = option$mle_solver,
    control = list(fnscale = -1) # Maximize the function
  )
  optim_converged <- (optim_result$convergence == 0L)
  if (!optim_converged) {
    warning("Optimization did not converge. The estimates may be meaningless.")
  }
  return(list(coef = optim_result$par))
}
